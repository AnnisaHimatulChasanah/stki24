{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4c21db-2b64-4650-9251-10e072cfe722",
   "metadata": {},
   "source": [
    "Perbandingan NLTK dan spaCy\n",
    "\n",
    "1. **Pendekatan Pemrosesan Teks**:\n",
    "   - NLTK adalah pustaka pemrosesan string. Ini menerima string sebagai input dan mengembalikan string atau daftar string sebagai output. \n",
    "   - Sementara itu, spaCy menggunakan pendekatan berorientasi objek. Ketika kita memproses teks, spaCy mengembalikan objek dokumen yang di dalamnya kata-kata dan kalimat adalah objek tersendiri.\n",
    "\n",
    "2. **Dukungan untuk Vektor Kata**:\n",
    "   - spaCy mendukung vektor kata (word vectors), sedangkan NLTK tidak memiliki dukungan untuk ini.\n",
    "\n",
    "3. **Tokenisasi Kata dan POS-Tagging**:\n",
    "   - Dalam tokenisasi kata dan penandaan POS (Part-of-Speech), spaCy lebih baik daripada NLTK.\n",
    "   - Namun, dalam tokenisasi kalimat, NLTK lebih unggul daripada spaCy.\n",
    "\n",
    "4. **Dukungan Bahasa**:\n",
    "   - NLTK mendukung berbagai bahasa.\n",
    "   - spaCy memiliki model statistik untuk 7 bahasa (Inggris, Jerman, Spanyol, Prancis, Portugis, Italia, dan Belanda). Selain itu, spaCy juga mendukung pengenalan entitas bernama (named entities) untuk beberapa bahasa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da904ae-8f8e-49d1-aec8-f01dd7236a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3a9284-66e5-4277-b011-d490eb7cf961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenize_wrapper(text):\n",
    "  return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ac78c4e-fca9-43a0-89c7-ee339fe7363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "teks_nltk = word_tokenize_wrapper('Yahya beserta teman-teman TK suka melihat lumba-lumba di Batang Dolphin Center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6286e935-1e4c-49f6-b93d-b47df77186b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yahya',\n",
       " 'beserta',\n",
       " 'teman-teman',\n",
       " 'TK',\n",
       " 'suka',\n",
       " 'melihat',\n",
       " 'lumba-lumba',\n",
       " 'di',\n",
       " 'Batang',\n",
       " 'Dolphin',\n",
       " 'Center']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teks_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5872bbf-3db0-4880-8264-10372852fa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacyNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading spacy-3.8.4-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.12-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.4-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.10.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (75.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (24.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.2.0-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\annis\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Downloading spacy-3.8.4-cp312-cp312-win_amd64.whl (11.8 MB)\n",
      "   ---------------------------------------- 0.0/11.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.8 MB 5.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.4/11.8 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.9/11.8 MB 6.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.0/11.8 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.0/11.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.3/11.8 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.9/11.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.2/11.8 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.8 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.8/11.8 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.12-cp312-cp312-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl (122 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 632.6/632.6 kB 7.9 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.4-cp312-cp312-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 1.3/1.5 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 6.4 MB/s eta 0:00:00\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading blis-1.2.0-cp312-cp312-win_amd64.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.3/6.3 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.6/6.3 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.9/6.3 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.5/6.3 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.3/5.4 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.6/5.4 MB 6.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.9/5.4 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 6.6 MB/s eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl (150 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, shellingham, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, language-data, typer, langcodes, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-1.2.0 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 preshed-3.0.9 shellingham-1.5.4 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 typer-0.15.1 wasabi-1.1.3 weasel-0.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10bb96ee-4a46-4067-a5a0-e808d5a97221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.id import Indonesian\n",
    "import spacy\n",
    "\n",
    "nlp = Indonesian()\n",
    "nlp = spacy.blank('id')\n",
    "Teks = nlp('Yahya beserta teman-teman TK suka melihat lumba-lumba di Batang Dolphin Center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ca28b2e-f000-4d90-9ec8-9d37d5eaecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Token_kata = [token.text for token in Teks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff8bc56f-15a9-4aa2-b97d-c41bd45e1b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yahya',\n",
       " 'beserta',\n",
       " 'teman-teman',\n",
       " 'TK',\n",
       " 'suka',\n",
       " 'melihat',\n",
       " 'lumba-lumba',\n",
       " 'di',\n",
       " 'Batang',\n",
       " 'Dolphin',\n",
       " 'Center']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Token_kata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82516d85-721b-43a6-8dab-55268c677e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de63132d-856f-4b18-a132-6163dfdccf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset_Sentimen_Emosi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ff2e472-c5de-420d-acff-870b9ce8b198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>Emosi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cegah mata rantai Covid-19,mari kita dirumah s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku mohon yaAllah semoga wabah covid-19 menghi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pemprov Papua Naikkan Status Jadi Tanggap Daru...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nyuruh orang pintar, lu aja Togog. Itu kerumun...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentimen  Emosi\n",
       "0  Cegah mata rantai Covid-19,mari kita dirumah s...       1.0      1\n",
       "1  aku mohon yaAllah semoga wabah covid-19 menghi...       1.0     -1\n",
       "2  Pemprov Papua Naikkan Status Jadi Tanggap Daru...       1.0      1\n",
       "3            Covid belum nyampe prigen mbak hmm hoax       0.0     -2\n",
       "4  Nyuruh orang pintar, lu aja Togog. Itu kerumun...      -1.0     -2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "487f0f57-b633-4860-90ba-dc3c45038fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Emosi'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44d2dda6-35fc-4eca-b805-fdb9e9c2d3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cegah mata rantai Covid-19,mari kita dirumah s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku mohon yaAllah semoga wabah covid-19 menghi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pemprov Papua Naikkan Status Jadi Tanggap Daru...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nyuruh orang pintar, lu aja Togog. Itu kerumun...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>Seluruh negara di dunia mengalami masa sulit k...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>Setelah covid dan skripsi disaster selesai, ma...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Malam ini!! Projek \"BENDA BOLEH BINCANG\" 9 mal...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>Pontang - panting di koyak covid 19</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>Masalahnya sekarang isu jangkitan covid. Alaaa...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>904 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweet  Sentimen\n",
       "0    Cegah mata rantai Covid-19,mari kita dirumah s...       1.0\n",
       "1    aku mohon yaAllah semoga wabah covid-19 menghi...       1.0\n",
       "2    Pemprov Papua Naikkan Status Jadi Tanggap Daru...       1.0\n",
       "3              Covid belum nyampe prigen mbak hmm hoax       0.0\n",
       "4    Nyuruh orang pintar, lu aja Togog. Itu kerumun...      -1.0\n",
       "..                                                 ...       ...\n",
       "899  Seluruh negara di dunia mengalami masa sulit k...       1.0\n",
       "900  Setelah covid dan skripsi disaster selesai, ma...       1.0\n",
       "901  Malam ini!! Projek \"BENDA BOLEH BINCANG\" 9 mal...       0.0\n",
       "902                Pontang - panting di koyak covid 19      -1.0\n",
       "903  Masalahnya sekarang isu jangkitan covid. Alaaa...      -1.0\n",
       "\n",
       "[904 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "def0dab8-ae70-4b65-8cc3-219c35ee4a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 904 entries, 0 to 903\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Tweet     904 non-null    object \n",
      " 1   Sentimen  903 non-null    float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 14.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8e40daa-2583-401e-bc0d-0f7342c4a11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ekphrasis\\classes\\tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
      "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annis\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ekphrasis\\classes\\exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n"
     ]
    }
   ],
   "source": [
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "text_processor = TextPreProcessor(\n",
    "    # istilah-istilah yang akan dinormalisasi (disesuaikan)\n",
    "    normalize=['email', 'percent', 'money', 'phone', 'user', 'time', 'date', 'number'],\n",
    "    \n",
    "    # istilah-istilah yang akan diberi anotasi (penanda khusus)\n",
    "    annotate={\"hashtag\"},  # hanya hashtag yang akan dianotasi\n",
    "    \n",
    "    fix_html=True,  # memperbaiki token HTML yang rusak\n",
    "    \n",
    "    # pemisahan kata menggunakan data dari Twitter\n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # koreksi ejaan menggunakan data dari Twitter\n",
    "    corrector=\"twitter\", \n",
    "    \n",
    "    # memisahkan kata dalam hashtag\n",
    "    unpack_hashtags=True,  # misalnya, #belajarkoding jadi 'belajar koding'\n",
    "    \n",
    "    # membongkar kontraksi (kata yang dipersingkat), misalnya 'can't' jadi 'can not'\n",
    "    unpack_contractions=True,  \n",
    "    \n",
    "    # tidak melakukan koreksi untuk kata yang terlalu panjang\n",
    "    spell_correct_elong=False,  # misalnya 'sooooo' tetap jadi 'so'\n",
    "    \n",
    "    # memilih pengurai kata (tokenizer), menggunakan SocialTokenizer yang disesuaikan untuk teks media sosial\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    \n",
    "    # kamus untuk mengganti token dalam teks (misalnya emotikon)\n",
    "    dicts=[emoticons]  # mengganti emotikon dengan bentuk yang lebih sesuai\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22893e53-5e45-46d1-907f-fc9452a01041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# panggil ekphrasis\n",
    "\n",
    "def bersih_data(text):\n",
    "    return \" \".join(text_processor.pre_process_doc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c2db737-6639-482c-a39e-0ae99b065096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:19: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:27: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:55: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:19: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:27: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:55: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\annis\\AppData\\Local\\Temp\\ipykernel_5588\\180390525.py:19: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  return re.sub('\\s+', ' ', text)\n",
      "C:\\Users\\annis\\AppData\\Local\\Temp\\ipykernel_5588\\180390525.py:27: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  return ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\", \" \", text).split())\n",
      "C:\\Users\\annis\\AppData\\Local\\Temp\\ipykernel_5588\\180390525.py:55: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  return re.sub('\\s+', ' ', text)\n"
     ]
    }
   ],
   "source": [
    "def non_ascii(text):\n",
    "    # Fungsi ini menghapus karakter non-ASCII dalam teks dan menggantinya dengan karakter pengganti\n",
    "    return text.encode('ascii', 'replace').decode('ascii')\n",
    "\n",
    "def remove_space_alzami(text):\n",
    "    # Fungsi ini menghapus spasi ekstra dan memastikan hanya ada satu spasi antar kata\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def remove_emoji_alzami(text):\n",
    "    # Fungsi ini menghapus emoji dan menggantinya dengan spasi\n",
    "    return ' '.join(re.sub(\"([x#][A-Za-z0-9]+)\", \" \", text).split())\n",
    "\n",
    "def remove_tab(text):\n",
    "    # Fungsi ini mengganti karakter tab (\\t), baris baru (\\n), karakter Unicode (\\u), dan backslash (\\) dengan spasi atau menghapusnya\n",
    "    return text.replace('\\\\t', \" \").replace('\\\\n', \" \").replace('\\\\u', \" \").replace('\\\\', \"\")\n",
    "\n",
    "def remove_tab2(text):\n",
    "    # Fungsi ini mengganti lebih dari satu spasi dengan satu spasi\n",
    "    return re.sub('\\s+', ' ', text)\n",
    "\n",
    "def remove_rt(text):\n",
    "    # Fungsi ini menghapus kata 'rt' dari teks\n",
    "    return text.replace('rt', \" \")\n",
    "\n",
    "def remove_mention(text):\n",
    "    # Fungsi ini menghapus mention (@username) dan URL dalam teks\n",
    "    return ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\", \" \", text).split())\n",
    "\n",
    "def remove_incomplete_url(text):\n",
    "    # Fungsi ini menghapus URL yang diawali dengan 'http://' atau 'https://'\n",
    "    return text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
    "\n",
    "def remove_single_char(text):\n",
    "    # Fungsi ini menghapus karakter tunggal (huruf) dalam teks\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "def remove_excessive_dot(text):\n",
    "    # Fungsi ini mengganti titik ganda (..) menjadi spasi\n",
    "    return text.replace('..', \" \")\n",
    "\n",
    "def change_stripe(text):\n",
    "    # Fungsi ini mengganti tanda minus (-) dengan spasi\n",
    "    return text.replace('-', \" \")\n",
    "\n",
    "def lower(text):\n",
    "    # Fungsi ini mengubah semua huruf dalam teks menjadi huruf kecil\n",
    "    return text.lower()\n",
    "\n",
    "def remove_whitespace_LT(text):\n",
    "    # Fungsi ini menghapus spasi di awal dan akhir teks\n",
    "    return text.strip()\n",
    "\n",
    "def remove_whitespace_multiple(text):\n",
    "    # Fungsi ini mengganti lebih dari satu spasi dengan satu spasi\n",
    "    return re.sub('\\s+', ' ', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    # Fungsi ini menghapus tanda baca dari teks, kecuali garis bawah (_)\n",
    "    remove = string.punctuation\n",
    "    remove = remove.replace(\"_\", \"\")  # Jangan hapus garis bawah\n",
    "    pattern = r\"[{}]\".format(remove)  # Membuat pola untuk tanda baca\n",
    "    return re.sub(pattern, \"\", text)  # Menghapus tanda baca sesuai pola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc36ce0b-9def-4360-ba8b-2c1fab825bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hapus untuk <>\n",
    "def remove_number_eks(text):\n",
    "    return text.replace('<number>',\" \")\n",
    "\n",
    "def remove_angka(text):\n",
    "    return re.sub(r\"\\d+\", \"\", text) \n",
    "\n",
    "def remove_URL_eks(text):\n",
    "    return text.replace('URL',\" \").replace('url',\" \")\n",
    "\n",
    "def space_punctuation(text):\n",
    "    return re.sub('(?<! )(?=[.,!?()])|(?<=[.,!?()])(?! )', r' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c477c97a-3cd3-4236-b87e-f4ca87eadad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "final_string = []\n",
    "s = \"\"\n",
    "for text in df['Tweet'].values:\n",
    "    filteredSentence = []\n",
    "    EachReviewText = \"\"\n",
    "    proc = lower(text)\n",
    "    proc = change_stripe(text)\n",
    "    proc = remove_emoji_alzami(proc)\n",
    "    proc = remove_tab(proc)\n",
    "    proc = remove_tab2(proc)\n",
    "    proc = non_ascii(proc)\n",
    "    proc = remove_incomplete_url(proc)\n",
    "    proc = remove_excessive_dot(proc)\n",
    "    proc = remove_whitespace_LT(proc)\n",
    "    proc = remove_whitespace_multiple(proc)\n",
    "    proc = remove_single_char(proc)\n",
    "    proc = space_punctuation(proc)\n",
    "    proc = remove_punctuation(proc)\n",
    "    proc = remove_space_alzami(proc)\n",
    "    proc = bersih_data(proc)\n",
    "    #proc = remove_rt(proc)\n",
    "    proc = remove_number_eks(proc)\n",
    "    proc = remove_angka(proc) \n",
    "    proc = remove_URL_eks(proc)\n",
    "    EachReviewText = proc\n",
    "    final_string.append(EachReviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44600a62-13f0-4a1a-b725-2ab9b3685fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"step01\"] = final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6fa5013-cd70-4b2a-afea-c36c403d4784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>step01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cegah mata rantai Covid-19,mari kita dirumah s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cegah mata rantai covid   mari kita dirumah sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku mohon yaAllah semoga wabah covid-19 menghi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aku mohon yaallah semoga wabah covid   menghil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pemprov Papua Naikkan Status Jadi Tanggap Daru...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pemprov papua naikkan status jadi tanggap daru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>covid belum nyampe prigen mbak hmm hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nyuruh orang pintar, lu aja Togog. Itu kerumun...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>nyuruh orang pintar lu aja togog itu kerumunan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pikir2 balik byk mnde plk nk setelkn lepas covid.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pikir balik byk mnde plk nk setelkn lepas covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Selamat pagi, hari jum'at. Jum'at keempat di k...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>selamat pagi hari jumat jumat keempat di kala ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hikmah di balik musibah covid-19, smg para pej...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hikmah di balik musibah covid   smg para pejab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cegah covid-19 beserta jajaran Polsek Kuranji ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cegah covid   beserta jajaran polsek kuranji m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ya Allah kami memohon pada mu perkenankanlah d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ya allah kami memohon pada mu perkenankanlah d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentimen  \\\n",
       "0  Cegah mata rantai Covid-19,mari kita dirumah s...       1.0   \n",
       "1  aku mohon yaAllah semoga wabah covid-19 menghi...       1.0   \n",
       "2  Pemprov Papua Naikkan Status Jadi Tanggap Daru...       1.0   \n",
       "3            Covid belum nyampe prigen mbak hmm hoax       0.0   \n",
       "4  Nyuruh orang pintar, lu aja Togog. Itu kerumun...      -1.0   \n",
       "5  Pikir2 balik byk mnde plk nk setelkn lepas covid.       0.0   \n",
       "6  Selamat pagi, hari jum'at. Jum'at keempat di k...       1.0   \n",
       "7  Hikmah di balik musibah covid-19, smg para pej...       1.0   \n",
       "8  Cegah covid-19 beserta jajaran Polsek Kuranji ...       1.0   \n",
       "9  Ya Allah kami memohon pada mu perkenankanlah d...       1.0   \n",
       "\n",
       "                                              step01  \n",
       "0  cegah mata rantai covid   mari kita dirumah sa...  \n",
       "1  aku mohon yaallah semoga wabah covid   menghil...  \n",
       "2  pemprov papua naikkan status jadi tanggap daru...  \n",
       "3            covid belum nyampe prigen mbak hmm hoax  \n",
       "4  nyuruh orang pintar lu aja togog itu kerumunan...  \n",
       "5    pikir balik byk mnde plk nk setelkn lepas covid  \n",
       "6  selamat pagi hari jumat jumat keempat di kala ...  \n",
       "7  hikmah di balik musibah covid   smg para pejab...  \n",
       "8  cegah covid   beserta jajaran polsek kuranji m...  \n",
       "9  ya allah kami memohon pada mu perkenankanlah d...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f0f4e72-31bf-496a-9a3e-29f5e6b002ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 904 entries, 0 to 903\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Tweet     904 non-null    object \n",
      " 1   Sentimen  903 non-null    float64\n",
      " 2   step01    904 non-null    object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 21.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Hapus data kosong\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb1a0d54-656d-4037-95d9-ec1cd62f1109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hapus = df[~df['step01'].str.contains(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "499edc88-7065-457c-ae43-e5da54977f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1 entries, 78 to 78\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Tweet     1 non-null      object \n",
      " 1   Sentimen  1 non-null      float64\n",
      " 2   step01    1 non-null      object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 32.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_hapus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fe79633-70af-4aa3-ab9c-7bd76dc2647e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>step01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>covid</td>\n",
       "      <td>0.0</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Tweet  Sentimen step01\n",
       "78  covid       0.0  covid"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hapus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49635f3a-32b7-4336-bb02-9598f5ad5433",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[~df.isin(df_hapus)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1436177d-73d4-4ce8-9d87-8744a4474e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 902 entries, 0 to 903\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Tweet     902 non-null    object \n",
      " 1   Sentimen  902 non-null    float64\n",
      " 2   step01    902 non-null    object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 28.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecf02195-97c5-46ab-8cfc-d8c1966ab4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>step01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cegah mata rantai Covid-19,mari kita dirumah s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cegah mata rantai covid   mari kita dirumah sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku mohon yaAllah semoga wabah covid-19 menghi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aku mohon yaallah semoga wabah covid   menghil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pemprov Papua Naikkan Status Jadi Tanggap Daru...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pemprov papua naikkan status jadi tanggap daru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>covid belum nyampe prigen mbak hmm hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nyuruh orang pintar, lu aja Togog. Itu kerumun...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>nyuruh orang pintar lu aja togog itu kerumunan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>Seluruh negara di dunia mengalami masa sulit k...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>seluruh negara di dunia mengalami masa sulit k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>Setelah covid dan skripsi disaster selesai, ma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>setelah covid dan skripsi disaster selesai mau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Malam ini!! Projek \"BENDA BOLEH BINCANG\" 9 mal...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>malam ini projek benda boleh bincang   malam d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>Pontang - panting di koyak covid 19</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>pontang panting di koyak covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>Masalahnya sekarang isu jangkitan covid. Alaaa...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>masalahnya sekarang isu jangkitan covid alaaaa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>902 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweet  Sentimen  \\\n",
       "0    Cegah mata rantai Covid-19,mari kita dirumah s...       1.0   \n",
       "1    aku mohon yaAllah semoga wabah covid-19 menghi...       1.0   \n",
       "2    Pemprov Papua Naikkan Status Jadi Tanggap Daru...       1.0   \n",
       "3              Covid belum nyampe prigen mbak hmm hoax       0.0   \n",
       "4    Nyuruh orang pintar, lu aja Togog. Itu kerumun...      -1.0   \n",
       "..                                                 ...       ...   \n",
       "899  Seluruh negara di dunia mengalami masa sulit k...       1.0   \n",
       "900  Setelah covid dan skripsi disaster selesai, ma...       1.0   \n",
       "901  Malam ini!! Projek \"BENDA BOLEH BINCANG\" 9 mal...       0.0   \n",
       "902                Pontang - panting di koyak covid 19      -1.0   \n",
       "903  Masalahnya sekarang isu jangkitan covid. Alaaa...      -1.0   \n",
       "\n",
       "                                                step01  \n",
       "0    cegah mata rantai covid   mari kita dirumah sa...  \n",
       "1    aku mohon yaallah semoga wabah covid   menghil...  \n",
       "2    pemprov papua naikkan status jadi tanggap daru...  \n",
       "3              covid belum nyampe prigen mbak hmm hoax  \n",
       "4    nyuruh orang pintar lu aja togog itu kerumunan...  \n",
       "..                                                 ...  \n",
       "899  seluruh negara di dunia mengalami masa sulit k...  \n",
       "900  setelah covid dan skripsi disaster selesai mau...  \n",
       "901  malam ini projek benda boleh bincang   malam d...  \n",
       "902                   pontang panting di koyak covid    \n",
       "903  masalahnya sekarang isu jangkitan covid alaaaa...  \n",
       "\n",
       "[902 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "191db699-dbfc-4633-a7b7-942cf1a4b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisasi kata slang menjadi kata baku\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70038d58-f8ad-4c91-abee-c6f387296c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenize_wrapper(text):\n",
    "  return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da41bd92-db74-4956-9d9d-43c55351fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['tokens'] = df['step01'].apply(word_tokenize_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9720ae02-7777-4422-81c5-9b5468c874d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>step01</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cegah mata rantai Covid-19,mari kita dirumah s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cegah mata rantai covid   mari kita dirumah sa...</td>\n",
       "      <td>[cegah, mata, rantai, covid, mari, kita, dirum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku mohon yaAllah semoga wabah covid-19 menghi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aku mohon yaallah semoga wabah covid   menghil...</td>\n",
       "      <td>[aku, mohon, yaallah, semoga, wabah, covid, me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pemprov Papua Naikkan Status Jadi Tanggap Daru...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pemprov papua naikkan status jadi tanggap daru...</td>\n",
       "      <td>[pemprov, papua, naikkan, status, jadi, tangga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>[covid, belum, nyampe, prigen, mbak, hmm, hoax]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nyuruh orang pintar, lu aja Togog. Itu kerumun...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>nyuruh orang pintar lu aja togog itu kerumunan...</td>\n",
       "      <td>[nyuruh, orang, pintar, lu, aja, togog, itu, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pikir2 balik byk mnde plk nk setelkn lepas covid.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pikir balik byk mnde plk nk setelkn lepas covid</td>\n",
       "      <td>[pikir, balik, byk, mnde, plk, nk, setelkn, le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Selamat pagi, hari jum'at. Jum'at keempat di k...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>selamat pagi hari jumat jumat keempat di kala ...</td>\n",
       "      <td>[selamat, pagi, hari, jumat, jumat, keempat, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hikmah di balik musibah covid-19, smg para pej...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hikmah di balik musibah covid   smg para pejab...</td>\n",
       "      <td>[hikmah, di, balik, musibah, covid, smg, para,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cegah covid-19 beserta jajaran Polsek Kuranji ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cegah covid   beserta jajaran polsek kuranji m...</td>\n",
       "      <td>[cegah, covid, beserta, jajaran, polsek, kuran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ya Allah kami memohon pada mu perkenankanlah d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ya allah kami memohon pada mu perkenankanlah d...</td>\n",
       "      <td>[ya, allah, kami, memohon, pada, mu, perkenank...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentimen  \\\n",
       "0  Cegah mata rantai Covid-19,mari kita dirumah s...       1.0   \n",
       "1  aku mohon yaAllah semoga wabah covid-19 menghi...       1.0   \n",
       "2  Pemprov Papua Naikkan Status Jadi Tanggap Daru...       1.0   \n",
       "3            Covid belum nyampe prigen mbak hmm hoax       0.0   \n",
       "4  Nyuruh orang pintar, lu aja Togog. Itu kerumun...      -1.0   \n",
       "5  Pikir2 balik byk mnde plk nk setelkn lepas covid.       0.0   \n",
       "6  Selamat pagi, hari jum'at. Jum'at keempat di k...       1.0   \n",
       "7  Hikmah di balik musibah covid-19, smg para pej...       1.0   \n",
       "8  Cegah covid-19 beserta jajaran Polsek Kuranji ...       1.0   \n",
       "9  Ya Allah kami memohon pada mu perkenankanlah d...       1.0   \n",
       "\n",
       "                                              step01  \\\n",
       "0  cegah mata rantai covid   mari kita dirumah sa...   \n",
       "1  aku mohon yaallah semoga wabah covid   menghil...   \n",
       "2  pemprov papua naikkan status jadi tanggap daru...   \n",
       "3            covid belum nyampe prigen mbak hmm hoax   \n",
       "4  nyuruh orang pintar lu aja togog itu kerumunan...   \n",
       "5    pikir balik byk mnde plk nk setelkn lepas covid   \n",
       "6  selamat pagi hari jumat jumat keempat di kala ...   \n",
       "7  hikmah di balik musibah covid   smg para pejab...   \n",
       "8  cegah covid   beserta jajaran polsek kuranji m...   \n",
       "9  ya allah kami memohon pada mu perkenankanlah d...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [cegah, mata, rantai, covid, mari, kita, dirum...  \n",
       "1  [aku, mohon, yaallah, semoga, wabah, covid, me...  \n",
       "2  [pemprov, papua, naikkan, status, jadi, tangga...  \n",
       "3    [covid, belum, nyampe, prigen, mbak, hmm, hoax]  \n",
       "4  [nyuruh, orang, pintar, lu, aja, togog, itu, k...  \n",
       "5  [pikir, balik, byk, mnde, plk, nk, setelkn, le...  \n",
       "6  [selamat, pagi, hari, jumat, jumat, keempat, d...  \n",
       "7  [hikmah, di, balik, musibah, covid, smg, para,...  \n",
       "8  [cegah, covid, beserta, jajaran, polsek, kuran...  \n",
       "9  [ya, allah, kami, memohon, pada, mu, perkenank...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3afd3732-761b-4630-ab50-c2e657d8d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_word = pd.read_csv('kamus_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27a57383-03cd-42b2-87f1-30b6219b70b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annis\\AppData\\Local\\Temp\\ipykernel_5588\\2408214049.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if row[0] not in normalized_word_dict:\n",
      "C:\\Users\\annis\\AppData\\Local\\Temp\\ipykernel_5588\\2408214049.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  normalized_word_dict[row[0]] = row[1]\n"
     ]
    }
   ],
   "source": [
    "normalized_word_dict = {}\n",
    "\n",
    "for index, row in normalized_word.iterrows():\n",
    "    if row[0] not in normalized_word_dict:\n",
    "        normalized_word_dict[row[0]] = row[1] \n",
    "\n",
    "def normalized_term(document):\n",
    "    return [normalized_word_dict[term] if term in normalized_word_dict else term for term in document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f7cf235-1bb2-417d-a763-578ef399a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['final_tokens'] = df_new['tokens'].apply(normalized_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad4bdcfd-7e91-48df-88fd-d564115efa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "final_string_tokens = []\n",
    "for text in df_new['final_tokens'].values:\n",
    "    EachReviewText = \"\"\n",
    "    EachReviewText = ' '.join(text)\n",
    "    final_string_tokens.append(EachReviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90ab1131-527c-4cb7-8238-cf94f1087ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"step02\"] = final_string_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28713aef-a2fa-468b-8609-27ca0511fdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentimen</th>\n",
       "      <th>step01</th>\n",
       "      <th>tokens</th>\n",
       "      <th>final_tokens</th>\n",
       "      <th>step02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cegah mata rantai Covid-19,mari kita dirumah s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cegah mata rantai covid   mari kita dirumah sa...</td>\n",
       "      <td>[cegah, mata, rantai, covid, mari, kita, dirum...</td>\n",
       "      <td>[cegah, mata, rantai, covid, mari, kita, dirum...</td>\n",
       "      <td>cegah mata rantai covid mari kita dirumah saja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aku mohon yaAllah semoga wabah covid-19 menghi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aku mohon yaallah semoga wabah covid   menghil...</td>\n",
       "      <td>[aku, mohon, yaallah, semoga, wabah, covid, me...</td>\n",
       "      <td>[aku, mohon, yaallah, semoga, wabah, covid, me...</td>\n",
       "      <td>aku mohon yaallah semoga wabah covid menghilan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pemprov Papua Naikkan Status Jadi Tanggap Daru...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pemprov papua naikkan status jadi tanggap daru...</td>\n",
       "      <td>[pemprov, papua, naikkan, status, jadi, tangga...</td>\n",
       "      <td>[pemprov, papua, naikkan, status, jadi, tangga...</td>\n",
       "      <td>pemprov papua naikkan status jadi tanggap daru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>covid belum nyampe prigen mbak hmm hoax</td>\n",
       "      <td>[covid, belum, nyampe, prigen, mbak, hmm, hoax]</td>\n",
       "      <td>[covid, belum, nyampe, prigen, mbak, hmm, hoax]</td>\n",
       "      <td>covid belum nyampe prigen mbak hmm hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nyuruh orang pintar, lu aja Togog. Itu kerumun...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>nyuruh orang pintar lu aja togog itu kerumunan...</td>\n",
       "      <td>[nyuruh, orang, pintar, lu, aja, togog, itu, k...</td>\n",
       "      <td>[nyuruh, orang, pintar, lu, aja, togog, itu, k...</td>\n",
       "      <td>nyuruh orang pintar lu aja togog itu kerumunan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pikir2 balik byk mnde plk nk setelkn lepas covid.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pikir balik byk mnde plk nk setelkn lepas covid</td>\n",
       "      <td>[pikir, balik, byk, mnde, plk, nk, setelkn, le...</td>\n",
       "      <td>[pikir, balik, byk, mnde, plk, nk, setelkn, le...</td>\n",
       "      <td>pikir balik byk mnde plk nk setelkn lepas covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Selamat pagi, hari jum'at. Jum'at keempat di k...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>selamat pagi hari jumat jumat keempat di kala ...</td>\n",
       "      <td>[selamat, pagi, hari, jumat, jumat, keempat, d...</td>\n",
       "      <td>[selamat, pagi, hari, jumat, jumat, keempat, d...</td>\n",
       "      <td>selamat pagi hari jumat jumat keempat di kala ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hikmah di balik musibah covid-19, smg para pej...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hikmah di balik musibah covid   smg para pejab...</td>\n",
       "      <td>[hikmah, di, balik, musibah, covid, smg, para,...</td>\n",
       "      <td>[hikmah, di, balik, musibah, covid, smg, para,...</td>\n",
       "      <td>hikmah di balik musibah covid smg para pejabat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cegah covid-19 beserta jajaran Polsek Kuranji ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cegah covid   beserta jajaran polsek kuranji m...</td>\n",
       "      <td>[cegah, covid, beserta, jajaran, polsek, kuran...</td>\n",
       "      <td>[cegah, covid, beserta, jajaran, polsek, kuran...</td>\n",
       "      <td>cegah covid beserta jajaran polsek kuranji mel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ya Allah kami memohon pada mu perkenankanlah d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ya allah kami memohon pada mu perkenankanlah d...</td>\n",
       "      <td>[ya, allah, kami, memohon, pada, mu, perkenank...</td>\n",
       "      <td>[ya, allah, kami, memohon, pada, mu, perkenank...</td>\n",
       "      <td>ya allah kami memohon pada mu perkenankanlah d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentimen  \\\n",
       "0  Cegah mata rantai Covid-19,mari kita dirumah s...       1.0   \n",
       "1  aku mohon yaAllah semoga wabah covid-19 menghi...       1.0   \n",
       "2  Pemprov Papua Naikkan Status Jadi Tanggap Daru...       1.0   \n",
       "3            Covid belum nyampe prigen mbak hmm hoax       0.0   \n",
       "4  Nyuruh orang pintar, lu aja Togog. Itu kerumun...      -1.0   \n",
       "5  Pikir2 balik byk mnde plk nk setelkn lepas covid.       0.0   \n",
       "6  Selamat pagi, hari jum'at. Jum'at keempat di k...       1.0   \n",
       "7  Hikmah di balik musibah covid-19, smg para pej...       1.0   \n",
       "8  Cegah covid-19 beserta jajaran Polsek Kuranji ...       1.0   \n",
       "9  Ya Allah kami memohon pada mu perkenankanlah d...       1.0   \n",
       "\n",
       "                                              step01  \\\n",
       "0  cegah mata rantai covid   mari kita dirumah sa...   \n",
       "1  aku mohon yaallah semoga wabah covid   menghil...   \n",
       "2  pemprov papua naikkan status jadi tanggap daru...   \n",
       "3            covid belum nyampe prigen mbak hmm hoax   \n",
       "4  nyuruh orang pintar lu aja togog itu kerumunan...   \n",
       "5    pikir balik byk mnde plk nk setelkn lepas covid   \n",
       "6  selamat pagi hari jumat jumat keempat di kala ...   \n",
       "7  hikmah di balik musibah covid   smg para pejab...   \n",
       "8  cegah covid   beserta jajaran polsek kuranji m...   \n",
       "9  ya allah kami memohon pada mu perkenankanlah d...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [cegah, mata, rantai, covid, mari, kita, dirum...   \n",
       "1  [aku, mohon, yaallah, semoga, wabah, covid, me...   \n",
       "2  [pemprov, papua, naikkan, status, jadi, tangga...   \n",
       "3    [covid, belum, nyampe, prigen, mbak, hmm, hoax]   \n",
       "4  [nyuruh, orang, pintar, lu, aja, togog, itu, k...   \n",
       "5  [pikir, balik, byk, mnde, plk, nk, setelkn, le...   \n",
       "6  [selamat, pagi, hari, jumat, jumat, keempat, d...   \n",
       "7  [hikmah, di, balik, musibah, covid, smg, para,...   \n",
       "8  [cegah, covid, beserta, jajaran, polsek, kuran...   \n",
       "9  [ya, allah, kami, memohon, pada, mu, perkenank...   \n",
       "\n",
       "                                        final_tokens  \\\n",
       "0  [cegah, mata, rantai, covid, mari, kita, dirum...   \n",
       "1  [aku, mohon, yaallah, semoga, wabah, covid, me...   \n",
       "2  [pemprov, papua, naikkan, status, jadi, tangga...   \n",
       "3    [covid, belum, nyampe, prigen, mbak, hmm, hoax]   \n",
       "4  [nyuruh, orang, pintar, lu, aja, togog, itu, k...   \n",
       "5  [pikir, balik, byk, mnde, plk, nk, setelkn, le...   \n",
       "6  [selamat, pagi, hari, jumat, jumat, keempat, d...   \n",
       "7  [hikmah, di, balik, musibah, covid, smg, para,...   \n",
       "8  [cegah, covid, beserta, jajaran, polsek, kuran...   \n",
       "9  [ya, allah, kami, memohon, pada, mu, perkenank...   \n",
       "\n",
       "                                              step02  \n",
       "0  cegah mata rantai covid mari kita dirumah saja...  \n",
       "1  aku mohon yaallah semoga wabah covid menghilan...  \n",
       "2  pemprov papua naikkan status jadi tanggap daru...  \n",
       "3            covid belum nyampe prigen mbak hmm hoax  \n",
       "4  nyuruh orang pintar lu aja togog itu kerumunan...  \n",
       "5    pikir balik byk mnde plk nk setelkn lepas covid  \n",
       "6  selamat pagi hari jumat jumat keempat di kala ...  \n",
       "7  hikmah di balik musibah covid smg para pejabat...  \n",
       "8  cegah covid beserta jajaran polsek kuranji mel...  \n",
       "9  ya allah kami memohon pada mu perkenankanlah d...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97596848-fa93-42d5-abf8-d4babac22704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan\n",
    "df.to_csv('clean_dataset2.csv',sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2686358a-57fd-4e40-9f68-9d0907bedaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
