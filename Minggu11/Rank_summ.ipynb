{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import networkx as nx\n",
    "from nltk.tokenize import  sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Maria Sharapova has basically no friends as te...\n",
       "1    BASEL, Switzerland (AP), Roger Federer advance...\n",
       "2    Roger Federer has revealed that organisers of ...\n",
       "3    Kei Nishikori will try to end his long losing ...\n",
       "4    Federer, 37, first broke through on tour over ...\n",
       "5    Nadal has not played tennis since he was force...\n",
       "6    Tennis giveth, and tennis taketh away. The end...\n",
       "7    Federer won the Swiss Indoors last week by bea...\n",
       "Name: article_text, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/tennis_articles_v4.csv')\n",
    "df['article_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Mengganti karakter non-alfabet dengan spasi\n",
    "s = 'he&&&s'\n",
    "s = re.sub(\"[^a-zA-Z]\", \" \", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pembersihan kalimat, menghapus karakter non-alfabet dan mengubah menjadi huruf kecil\n",
    "\n",
    "dict = {}  # Dictionary untuk menyimpan kalimat asli\n",
    "s = \"\"  # Inisialisasi string kosong\n",
    "\n",
    "# Menggabungkan semua teks artikel menjadi satu string\n",
    "for a in df['article_text']:\n",
    "    s += a\n",
    "s = s.lower()  # Mengubah seluruh teks menjadi huruf kecil\n",
    "\n",
    "# Memecah teks menjadi kalimat-kalimat\n",
    "sentences = sent_tokenize(s)\n",
    "\n",
    "final = []  # Daftar untuk menyimpan kalimat yang sudah dibersihkan\n",
    "\n",
    "# Membersihkan setiap kalimat dan menyimpannya dalam 'final' dan 'dict'\n",
    "for s in sentences:\n",
    "    temp = re.sub(\"[^a-zA-Z]\", \" \", s)  # Hapus karakter non-alfabet\n",
    "    temp = temp.lower()  # Ubah kalimat menjadi huruf kecil\n",
    "    final.append(temp)  # Tambahkan kalimat yang dibersihkan\n",
    "    dict[temp] = s  # Simpan kalimat asli dengan kata yang dibersihkan sebagai key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menghitung kemiripan antara dua kalimat menggunakan vektor kata\n",
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []  # Jika tidak ada stopwords, buat list kosong\n",
    "    \n",
    "    # Membuat daftar kata untuk kedua kalimat dan mengubahnya ke huruf kecil\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "\n",
    "    # Gabungkan semua kata unik dari kedua kalimat\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "\n",
    "    # Membuat vektor kosong untuk kedua kalimat\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "\n",
    "    # Isi vektor untuk kalimat pertama berdasarkan kata yang ada\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    "\n",
    "    # Isi vektor untuk kalimat kedua berdasarkan kata yang ada\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    "\n",
    "    # Mengembalikan jarak kosinus antara kedua kalimat\n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    "\n",
    "# Fungsi untuk membuat matriks kemiripan antar kalimat\n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    # Membuat matriks kosong dengan ukuran len(sentences) x len(sentences)\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "\n",
    "    # Mengisi matriks dengan kemiripan antar kalimat\n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2:  # Lewati jika kalimat yang dibandingkan adalah kalimat yang sama\n",
    "                continue \n",
    "            # Menghitung kemiripan kalimat idx1 dan idx2\n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "    \n",
    "    return similarity_matrix  # Mengembalikan matriks kemiripan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghasilkan ringkasan teks dengan menggunakan algoritma PageRank untuk menentukan kalimat-kalimat yang paling penting dalam sebuah dokumen\n",
    "\n",
    "# Step 2 - Membuat Matriks Kemiripan Antar Kalimat\n",
    "sentence_similarity_martix = build_similarity_matrix(final, '')\n",
    "\n",
    "# Step 3 - Memberi Peringkat pada Kalimat\n",
    "sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "\n",
    "# Step 4 - Menyortir Kalimat Berdasarkan Peringkat\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(final)), reverse=True)    \n",
    "\n",
    "# Step 5 - Menghasilkan Ringkasan\n",
    "# print('Summarize Text: \\n', \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argentina and britain received wild cards to the new-look event, and will compete along with the four 2018 semi-finalists and the 12 teams who win qualifying rounds next february.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "     print(dict[ranked_sentence[i][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
